{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset Visualization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KungFuPanda22/CNN_Devanagiri/blob/master/Dataset_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nVaVWGQTZlo",
        "colab_type": "text"
      },
      "source": [
        "#Libraries\n",
        "These are all the libraries we need to import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zHM1KlgP5nH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "from six.moves import cPickle as pickle\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import time\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJQdGM9CQdm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import decomposition\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whTTXmRmTf8N",
        "colab_type": "text"
      },
      "source": [
        "#Data Storage\n",
        "\n",
        "This section of code reads the Devnagiri Dataset and stores it in an array and randomizes it and then standardizes it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRhH8--qVtAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extracting Devnagiri Data\n",
        "\n",
        "num_classes = 18\n",
        "np.random.seed(133)\n",
        "\n",
        "def maybe_extract(filename, force=False):\n",
        "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
        "  if os.path.isdir(root) and not force:\n",
        "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
        "  else:\n",
        "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
        "    tar = tarfile.open(filename)\n",
        "    sys.stdout.flush()\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "  data_folders = [\n",
        "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
        "    if os.path.isdir(os.path.join(root, d))]\n",
        "  if len(data_folders) != num_classes:\n",
        "    raise Exception(\n",
        "      'Expected %d folders, one per class. Found %d instead.' % (\n",
        "        num_classes, len(data_folders)))\n",
        "  print(data_folders)\n",
        "  return data_folders\n",
        "  \n",
        "train_folders = maybe_extract('Train.tar.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8w-KyRJWC7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 32  # Pixel width and height.\n",
        "pixel_depth = 255.0  # Number of levels per pixel.\n",
        "\n",
        "#Storing data in NumPy array\n",
        "\n",
        "def load_letter(folder, min_num_images):\n",
        "  \"\"\"Load the data for a single letter label.\"\"\"\n",
        "  image_files = os.listdir(folder)\n",
        "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
        "                         dtype=np.float32)\n",
        "  print(folder)\n",
        "  num_images = 0\n",
        "  for image in image_files:\n",
        "    image_file = os.path.join(folder, image)\n",
        "    try:\n",
        "      image_data = (plt.imread(image_file,0).astype(float)) / pixel_depth\n",
        "      if image_data.shape != (image_size, image_size):\n",
        "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
        "      dataset[num_images, :, :] = image_data\n",
        "      num_images = num_images + 1\n",
        "    except IOError as e:\n",
        "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
        "    \n",
        "  dataset = dataset[0:num_images, :, :]\n",
        "  if num_images < min_num_images:\n",
        "    raise Exception('Many fewer images than expected: %d < %d' %\n",
        "                    (num_images, min_num_images))\n",
        "    \n",
        "  print('Full dataset tensor:', dataset.shape)\n",
        "  print('Mean:', np.mean(dataset))\n",
        "  print('Standard deviation:', np.std(dataset))\n",
        "  return dataset\n",
        "        \n",
        "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
        "  dataset_names = []\n",
        "  for folder in data_folders:\n",
        "    set_filename = folder + '.pickle'\n",
        "    dataset_names.append(set_filename)\n",
        "    if os.path.exists(set_filename) and not force:\n",
        "      print('%s already present - Skipping pickling.' % set_filename)\n",
        "    else:\n",
        "      print('Pickling %s.' % set_filename)\n",
        "      dataset = load_letter(folder, min_num_images_per_class)\n",
        "      try:\n",
        "        with open(set_filename, 'wb') as f:\n",
        "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
        "      except Exception as e:\n",
        "        print('Unable to save data to', set_filename, ':', e)\n",
        "  \n",
        "  return dataset_names\n",
        "\n",
        "train_datasets = maybe_pickle(train_folders, 1700)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhMePTe_YWte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_arrays(nb_rows, img_size):\n",
        "  if nb_rows:\n",
        "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
        "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
        "  else:\n",
        "    dataset, labels = None, None\n",
        "  return dataset, labels\n",
        "\n",
        "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
        "  num_classes = len(pickle_files)\n",
        "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
        "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
        "  vsize_per_class = valid_size // num_classes\n",
        "  tsize_per_class = train_size // num_classes\n",
        "    \n",
        "  start_v, start_t = 0, 0\n",
        "  end_v, end_t = vsize_per_class, tsize_per_class\n",
        "  end_l = vsize_per_class+tsize_per_class\n",
        "  for label, pickle_file in enumerate(pickle_files):       \n",
        "    try:\n",
        "      with open(pickle_file, 'rb') as f:\n",
        "        letter_set = pickle.load(f)\n",
        "        # let's shuffle the letters to have random validation and training set\n",
        "        np.random.shuffle(letter_set)\n",
        "        if valid_dataset is not None:\n",
        "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
        "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
        "          valid_labels[start_v:end_v] = label\n",
        "          start_v += vsize_per_class\n",
        "          end_v += vsize_per_class\n",
        "                    \n",
        "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
        "        train_dataset[start_t:end_t, :, :] = train_letter\n",
        "        train_labels[start_t:end_t] = label\n",
        "        start_t += tsize_per_class\n",
        "        end_t += tsize_per_class\n",
        "    except Exception as e:\n",
        "      print('Unable to process data from', pickle_file, ':', e)\n",
        "      raise\n",
        "    \n",
        "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
        "\n",
        "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(train_datasets, 30600,0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVWgMtvd1Hap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Randodmize the Dataset\n",
        "\n",
        "def randomize(dataset, labels):\n",
        "  permutation = np.random.permutation(labels.shape[0])\n",
        "  shuffled_dataset = dataset[permutation,:,:]\n",
        "  shuffled_labels = labels[permutation]\n",
        "  return shuffled_dataset, shuffled_labels\n",
        "train_dataset, train_labels = randomize(train_dataset, train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffg-uzkY2COW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = train_dataset.reshape(train_dataset.shape[0],1024)\n",
        "sc = StandardScaler()\n",
        "train_dataset = sc.fit_transform(train_dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdKKY1wqpYEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrS0WxaBUcaf",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualization - Principal Component Analysis\n",
        "\n",
        "First, we apply Principal Component Analysis(PCA) on the dataset. The dataset has 1024 features for each example. For the first step, we try to apply PCA and reduce the no. of components to two. In the second step, we reduce the components to three and make a 3D plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13WWjr1d1HZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Linear dimensionality reduction model\n",
        "pca_2=decomposition.PCA(n_components = 2)\n",
        "\n",
        "pca_2.fit(train_dataset)\n",
        "\n",
        "pca_results_2 = pca_2.transform(train_dataset)\n",
        "\n",
        "pca_2.explained_variance_ratio_.cumsum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YjlSOyjQwLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2D plot of 18 different classes (Each color denotes a different class)\n",
        "\n",
        "plt.figure(figsize=[15,15])\n",
        "plt.scatter(pca_results_2[:, 0], pca_results_2[:, 1],\n",
        "            c=train_labels, edgecolor='none', alpha=0.5,\n",
        "            cmap=plt.cm.get_cmap('nipy_spectral', 18), s = 7)\n",
        "plt.xlabel('component 1')\n",
        "plt.ylabel('component 2')\n",
        "plt.colorbar();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqUQzf-vWRw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca_3=decomposition.PCA(n_components = 3)\n",
        "\n",
        "pca_3.fit(train_dataset)\n",
        "\n",
        "pca_results_3 = pca_3.transform(train_dataset)\n",
        "\n",
        "pca_3.explained_variance_ratio_.cumsum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lytv4Mn27EnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2D plot of 18 different classes (Each color denotes a different class)\n",
        "\n",
        "fig = plt.figure(figsize = [15,15])\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(xs=pca_results_3[:, 0], ys= pca_results_3[:, 1], zs=pca_results_3[:, 2], zdir='z', \n",
        "           s=7,cmap=plt.cm.get_cmap('nipy_spectral', 18), c=train_labels, depthshade=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJZavDGiWm4C",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualization - t-distributed Stochastic Neighbor Embedding\n",
        "\n",
        "Now we apply t-distributed stochastic neighbor embedding(t-SNE) on the dataset. The dataset has 1024 features for each example. For the first step, we try to apply t-SNE and reduce the no. of components to two. In the second step, we reduce the components to three and make a 3D plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ln2Jixae364",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_start = time.time()\n",
        "tsne_2 = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results_2 = tsne.fit_transform(train_dataset)\n",
        "\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pIqSxhpRn-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2D plot of 18 different classes (Each color denotes a different class)\n",
        "\n",
        "plt.figure(figsize=[15,15])\n",
        "plt.scatter(tsne_results_2[:, 0], tsne_results_2[:, 1],\n",
        "            c=train_labels, edgecolor='none', alpha=0.5,\n",
        "            cmap=plt.cm.get_cmap('nipy_spectral', 18))\n",
        "plt.xlabel('component 1')\n",
        "plt.ylabel('component 2')\n",
        "plt.colorbar();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO4UmP65Xfh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_start = time.time()\n",
        "tsne_3 = TSNE(n_components=3, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results_3 = tsne.fit_transform(train_dataset)\n",
        "\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfii5rqxSK5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3D plot of 18 different classes (Each color denotes a different class)\n",
        "\n",
        "fig = plt.figure(figsize = [15,15])\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(xs=tsne_results_3[:, 0], ys= tsne_results_3[:, 1], zs=tsne_results_3[:, 2], zdir='z',\n",
        "           s=7,cmap=plt.cm.get_cmap('nipy_spectral', 18), c=train_labels, depthshade=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXMIjhQPX5BY",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualization - PCA + t-SNE\n",
        "\n",
        "Here, we first use PCA to reduce the components to 75 and then use t-SNE to reduce components to 2 and 3 respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbdLoIy0X4sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Linear dimensionality reduction model\n",
        "pca_74=decomposition.PCA(n_components = 75)\n",
        "\n",
        "pca_75.fit(train_dataset)\n",
        "\n",
        "pca_results_75 = pca_2.transform(train_dataset)\n",
        "\n",
        "pca_75.explained_variance_ratio_.cumsum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eapHnpYtd3xM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_start = time.time()\n",
        "tsne_75_2 = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results_75_2 = tsne.fit_transform(pca_results_75)\n",
        "\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt52H2LXd9Fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2D plot of 18 different classes (Each color denotes a different class)\n",
        "\n",
        "plt.figure(figsize=[15,15])\n",
        "plt.scatter(tsne_results_75_2[:, 0], tsne_results_75_2[:, 1],\n",
        "            c=train_labels, edgecolor='none', alpha=0.5,\n",
        "            cmap=plt.cm.get_cmap('nipy_spectral', 18))\n",
        "plt.xlabel('component 1')\n",
        "plt.ylabel('component 2')\n",
        "plt.colorbar();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtJpFiyeeGLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_start = time.time()\n",
        "tsne_75_3 = TSNE(n_components=3, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results_75_3 = tsne.fit_transform(pca_results_75)\n",
        "\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maQkKpOpeGAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3D plot of 18 different classes (Each color denotes a different class)\n",
        "\n",
        "fig = plt.figure(figsize = [15,15])\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(xs=tsne_results_75_3[:, 0], ys= tsne_results_75_3[:, 1], zs=tsne_results_75_3[:, 2], zdir='z',\n",
        "           s=7,cmap=plt.cm.get_cmap('nipy_spectral', 18), c=train_labels, depthshade=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}